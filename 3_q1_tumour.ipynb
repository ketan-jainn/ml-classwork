{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"qvfZg3LQbD-5","executionInfo":{"status":"ok","timestamp":1690609555897,"user_tz":-330,"elapsed":2206,"user":{"displayName":"Ketan Jain 22MCA0417","userId":"12308045846389162988"}}},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOD8wzKVSFig","outputId":"befb9e9f-3685-4b06-da21-0690863b82a5","executionInfo":{"status":"ok","timestamp":1690609555897,"user_tz":-330,"elapsed":24,"user":{"displayName":"Ketan Jain 22MCA0417","userId":"12308045846389162988"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open /content/brain_tumour.zip, /content/brain_tumour.zip.zip or /content/brain_tumour.zip.ZIP.\n"]}],"source":["!unzip /content/brain_tumour.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"ClebU9NJg99G","outputId":"70c40328-1864-465b-cf39-c107eaed034e","executionInfo":{"status":"error","timestamp":1690609555898,"user_tz":-330,"elapsed":9,"user":{"displayName":"Ketan Jain 22MCA0417","userId":"12308045846389162988"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-43d8267d5584>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Flow training images in batches of 128 using train_datagen generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m'/content/Training'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# This is the source directory for training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# All images will be resized to 150x150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \"\"\"\n\u001b[0;32m-> 1648\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Training'"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255)\n","\n","testing_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        '/content/Training',  # This is the source directory for training images\n","        target_size=(224, 224),  # All images will be resized to 150x150\n","        class_mode='categorical')\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","testing_generator = testing_datagen.flow_from_directory(\n","        '/content/Testing',  # This is the source directory for training images\n","        target_size=(224, 224),  # All images will be resized to 150x150\n","        class_mode='categorical')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fb1_lgobv81m","executionInfo":{"status":"aborted","timestamp":1690609555899,"user_tz":-330,"elapsed":9,"user":{"displayName":"Ketan Jain 22MCA0417","userId":"12308045846389162988"}}},"outputs":[],"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.Dense(64, activation='relu'))  # other activation function can be sigmoid, tanh\n","model.add(layers.Dense(4, activation='softmax'))\n","model.summary()\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.categorical_crossentropy,\n","              metrics=['accuracy'])     # for binary classification: binary_crossentropy"]},{"cell_type":"code","source":["model_history = model.fit(\n","train_generator,\n","epochs = 30,\n","validation_data=testing_generator)"],"metadata":{"id":"jw0DUR8q-xBP","executionInfo":{"status":"aborted","timestamp":1690609555899,"user_tz":-330,"elapsed":9,"user":{"displayName":"Ketan Jain 22MCA0417","userId":"12308045846389162988"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BfhejIVdk2Lg","executionInfo":{"status":"aborted","timestamp":1690609555899,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ketan Jain 22MCA0417","userId":"12308045846389162988"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = model_history.history['accuracy']\n","val_acc = model_history.history['val_accuracy']\n","loss = model_history.history['loss']\n","val_loss = model_history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Val accuracy')\n","plt.title('Training Accuracy')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training L+oss')\n","plt.plot(epochs, val_loss, 'b', label='Val Loss')\n","plt.title('Training Loss')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"7FCIpZOUCWwo","executionInfo":{"status":"aborted","timestamp":1690609555900,"user_tz":-330,"elapsed":9,"user":{"displayName":"Ketan Jain 22MCA0417","userId":"12308045846389162988"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1Q6sTB6xNWp1BUzJt0kz69-uRvvSn1O2_","timestamp":1690605958703}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}