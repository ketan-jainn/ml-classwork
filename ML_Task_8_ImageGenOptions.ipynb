{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qvfZg3LQbD-5"},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOD8wzKVSFig"},"outputs":[],"source":["!unzip /content/corn"]},{"cell_type":"markdown","source":["**ImageDataGenerator options**\n","\n","\n","featurewise_center=False,\n","samplewise_center=False,\n","featurewise_std_normalization=False,\n","samplewise_std_normalization=False,\n","zca_whitening=False,\n","zca_epsilon=1e-06,\n","rotation_range=0,\n","width_shift_range=0.0,\n","height_shift_range=0.0,\n","brightness_range=None,\n","shear_range=0.0,\n","zoom_range=0.0,\n","channel_shift_range=0.0,\n","fill_mode='nearest',\n","cval=0.0,\n","horizontal_flip=False,\n","vertical_flip=False,\n","rescale=None,\n","preprocessing_function=None,\n","data_format=None,\n","validation_split=0.0,\n","interpolation_order=1,\n","dtype=None\n","\n","\n","\n","\n","    featurewise_center: Boolean. Set to True if you want to subtract the mean of the whole dataset from each feature.\n","    samplewise_center: Boolean. Set to True if you want to subtract the mean of each individual sample/image from itself.\n","    featurewise_std_normalization: Boolean. Set to True to divide inputs by the standard deviation of the whole dataset.\n","    samplewise_std_normalization: Boolean. Set to True to divide each individual sample/image by its own standard deviation.\n","    zca_whitening: Boolean. Set to True to apply ZCA whitening, which helps decorrelate features in the input data.\n","    zca_epsilon: Float. Epsilon for ZCA whitening, usually set to a small value like 1e-06.\n","    rotation_range: Int. Range for random rotations in degrees (e.g., 40 means rotation between -40 and +40 degrees).\n","    width_shift_range: Float or Tuple. Range for horizontal random shifts as a fraction of the width or as an absolute number of pixels.\n","    height_shift_range: Float or Tuple. Range for vertical random shifts as a fraction of the height or as an absolute number of pixels.\n","    brightness_range: Tuple. Range for random brightness augmentation.\n","    shear_range: Float. Range for random shearing in degrees.\n","    zoom_range: Float or Tuple. Range for random zooming (e.g., 0.2 means zoom between 0.8 and 1.2).\n","    channel_shift_range: Float. Range for random channel shifts.\n","    fill_mode: String. How to fill the newly created pixels after rotation or shifting. Options: 'nearest', 'constant', 'reflect', 'wrap'.\n","    cval: Float. Value used for points outside the boundaries when fill_mode is 'constant'.\n","    horizontal_flip: Boolean. Set to True for random horizontal flipping.\n","    vertical_flip: Boolean. Set to True for random vertical flipping.\n","    rescale: Float. Rescaling factor applied to the input data.\n","    preprocessing_function: Function. Custom function for data preprocessing.\n","    data_format: String. Image data format ('channels_last' or 'channels_first').\n","    validation_split: Float. Fraction of images to reserve for validation if using validation_split with ImageDataGenerator.\n","    interpolation_order: Int. Interpolation order used in image transformations.\n","    dtype: Data type to use for the generated arrays.\n","\n","The selection and recommended values of these augmentation techniques depend on the specific dataset, the nature of the images, and the problem you are trying to solve. For example:\n","\n","    Use featurewise_center, featurewise_std_normalization, or zca_whitening when you want to normalize the entire dataset to have zero mean or uncorrelated features.\n","    Use horizontal_flip and/or vertical_flip when the images are not direction-sensitive (e.g., many natural scenes).\n","    Use rotation_range, width_shift_range, height_shift_range, and zoom_range to introduce more variations in the dataset.\n","    The value for each parameter can vary based on the dataset and the level of augmentation you want. It's often best to experiment with different values and observe the effects on the performance of your model.\n","\n","The choice of data augmentation techniques should be guided by the nature of the data and the potential benefits they can bring to the model's generalization ability. You may want to start with a minimal set of augmentations and gradually introduce more if necessary. Always monitor the performance of your model on a validation set to avoid overfitting."],"metadata":{"id":"mRvemLA_o-PV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ClebU9NJg99G"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,)\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        '/content/corn/train',  # This is the source directory for training images\n","        target_size=(224, 224),  # All images will be resized to 150x150\n","        class_mode='categorical')\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","validation_generator = validation_datagen.flow_from_directory(\n","        '/content/corn/val',  # This is the source directory for training images\n","        target_size=(224, 224),  # All images will be resized to 150x150\n","        class_mode='categorical')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fb1_lgobv81m"},"outputs":[],"source":["model = tf.keras.applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n","#Adding custom Layers\n","x = model.output\n","x = tf.keras.layers.Flatten()(x)\n","x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n","predictions = tf.keras.layers.Dense(4, activation=\"softmax\")(x)\n","model = tf.keras.Model(inputs = model.input, outputs = predictions)\n","model.summary()\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.categorical_crossentropy,\n","              metrics=['accuracy'])"]},{"cell_type":"code","source":["model_history = model.fit(\n","train_generator,\n","epochs = 30,\n","validation_data = validation_generator)"],"metadata":{"id":"jw0DUR8q-xBP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BfhejIVdk2Lg"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = model_history.history['accuracy']\n","val_acc = model_history.history['val_accuracy']\n","loss = model_history.history['loss']\n","val_loss = model_history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Val accuracy')\n","plt.title('Training Accuracy')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Val Loss')\n","plt.title('Training Loss')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"7FCIpZOUCWwo"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}